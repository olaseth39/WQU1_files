{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1670577d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "matplotlib.rcParams['savefig.dpi'] = 144"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746e3d29",
   "metadata": {},
   "source": [
    "### Importing and Exporting Files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1349fee5",
   "metadata": {},
   "source": [
    "Most often data will be stored in a file, either locally on the computer or online. We'll learn how to read and write data to files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af43743d",
   "metadata": {},
   "source": [
    "### Python file handle(open)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f48837",
   "metadata": {},
   "source": [
    "In Python we interact with files on disk using the commands open and close. We've included a file in the data folder called sample.txt. Let's open it and read its contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a270c02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello!\n",
      "Congratulations!\n",
      "You've read data from file.\n",
      "<_io.TextIOWrapper name='./sample.txt' mode='r' encoding='cp1252'>\n"
     ]
    }
   ],
   "source": [
    "f = open('./sample.txt', 'r')\n",
    "data = f.read()\n",
    "f.close()\n",
    "\n",
    "print(data)\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6aea0c",
   "metadata": {},
   "source": [
    "Notice that we open the file and assign it to f, read the data from f. What is f? it's called a file handle. It's an object that connect the interpreter to the file we open. We read the data using this connection, and then once we're done with close the connection. It's a good habit to close a file handle once we're done with it, so usually we will do it automatically using Python's with keyword."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4e704c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello!\n",
      "Congratulations!\n",
      "You've read data from file.\n"
     ]
    }
   ],
   "source": [
    "#f is automatically closed\n",
    "#at the end of the body of the with statement\n",
    "with open('./sample.txt', 'r') as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "754d8717",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "I/O operation on closed file.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [15]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#using the with command closes the file automatically\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: I/O operation on closed file."
     ]
    }
   ],
   "source": [
    "#using the with command closes the file automatically\n",
    "f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7e40e0",
   "metadata": {},
   "source": [
    "We can also read individual lines of a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "22751972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello!\n",
      "\n",
      "Congratulations!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#at the end of the body of the with statement\n",
    "with open('./sample.txt', 'r') as f:\n",
    "    print(f.readline())\n",
    "    print(f.readline())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521c95cc",
   "metadata": {},
   "source": [
    "We can also read the entire page with readlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "49e9bccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello!\\n', 'Congratulations!\\n', \"You've read data from file.\"]\n"
     ]
    }
   ],
   "source": [
    "with open('./sample.txt', 'r') as f:\n",
    "    print(f.readlines())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13bafe3",
   "metadata": {},
   "source": [
    "However, the difference between read and readlines is that .read() returns a str while .readlines() returns a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3fa2f45f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "with open('./sample.txt', 'r') as f:\n",
    "    print(type(f.readlines()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9d27d8d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "with open('./sample.txt', 'r') as f:\n",
    "    print(type(f.read()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6542615",
   "metadata": {},
   "source": [
    "Writing to files is very similar. The main difference is when we open the file, we will use the 'w' flag instead of 'r'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5885c2b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a new file.\n",
      "I am practicing writing data to disk.\n"
     ]
    }
   ],
   "source": [
    "with open('./my_data.txt', 'w') as f:\n",
    "    f.write('This is a new file.\\n')\n",
    "    f.write('I am practicing writing data to disk.')\n",
    "    \n",
    "with open('./my_data.txt', 'r') as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5035cbcf",
   "metadata": {},
   "source": [
    "No matter how often we execute the above cell, the same output gets printed. Opening the file with the 'w' flag will overwrite the contents of the file. If we want to add to what is already in the file, we have to open the fiule with the 'a' flag ('a' stands for append)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "48e0c1ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a new file.\n",
      "I am practicing writing data to disk.\n",
      " Adding a new line.\n",
      " Adding a new line.\n",
      "Adding a new line.\n"
     ]
    }
   ],
   "source": [
    "with open('./my_data.txt', 'a') as f:\n",
    "    f.write('\\nAdding a new line.')\n",
    "    \n",
    "with open('./my_data.txt', 'r') as f:\n",
    "    data = f.read()\n",
    "    \n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2f7d6f",
   "metadata": {},
   "source": [
    "If we open a a data with r+ flag we can write to the file as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2dd33af9",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './fail.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [30]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./fail.txt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr+\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m      2\u001b[0m     f\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThis will not fail\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./fail.txt\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './fail.txt'"
     ]
    }
   ],
   "source": [
    "with open('./fail.txt', 'r+') as f:\n",
    "    f.write('This will not fail')\n",
    "    \n",
    "with open('./fail.txt', 'r') as f:\n",
    "    data = f.read()\n",
    "    \n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e907a5d",
   "metadata": {},
   "source": [
    "### OS module"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d265df7c",
   "metadata": {},
   "source": [
    "Python has a module for navigating the computer's file system called os. There are many useful tools in the os module, but there are two functions that are most useful for finding files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed5bf7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75e0d9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dir(os)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73a21c8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints',\n",
       " 'DS_IO.ipynb',\n",
       " 'Hash_function.ipynb',\n",
       " 'my_data.txt',\n",
       " 'PY_Algorithms.ipynb',\n",
       " 'PY_OOP.ipynb',\n",
       " 'PY_Pythonic.ipynb',\n",
       " 'Roughwork.ipynb',\n",
       " 'sample.txt',\n",
       " 'stock_prices.csv',\n",
       " 'WQU_unit _one.ipynb']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b454eb",
   "metadata": {},
   "source": [
    "The command listdir is the simpler of the two functions we'll cover. It simply lists the contents of the directory path we specify. When we pass '.' as the argument, listdir will look in the current directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6797b73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.walk?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d273e545",
   "metadata": {},
   "source": [
    "Signature: os.walk(top, topdown=True, onerror=None, followlinks=False)\n",
    "Docstring:\n",
    "Directory tree generator.\n",
    "\n",
    "For each directory in the directory tree rooted at top (including top\n",
    "itself, but excluding '.' and '..'), yields a 3-tuple\n",
    "\n",
    "    dirpath, dirnames, filenames\n",
    "\n",
    "dirpath is a string, the path to the directory.  dirnames is a list of\n",
    "the names of the subdirectories in dirpath (excluding '.' and '..').\n",
    "filenames is a list of the names of the non-directory files in dirpath.\n",
    "Note that the names in the lists are just names, with no path components.\n",
    "To get a full path (which begins with top) to a file or directory in\n",
    "dirpath, do os.path.join(dirpath, name).\n",
    "\n",
    "If optional arg 'topdown' is true or not specified, the triple for a\n",
    "directory is generated before the triples for any of its subdirectories\n",
    "(directories are generated top down).  If topdown is false, the triple\n",
    "for a directory is generated after the triples for all of its\n",
    "subdirectories (directories are generated bottom up).\n",
    "\n",
    "When topdown is true, the caller can modify the dirnames list in-place\n",
    "(e.g., via del or slice assignment), and walk will only recurse into the\n",
    "subdirectories whose names remain in dirnames; this can be used to prune the\n",
    "search, or to impose a specific order of visiting.  Modifying dirnames when\n",
    "topdown is false has no effect on the behavior of os.walk(), since the\n",
    "directories in dirnames have already been generated by the time dirnames\n",
    "itself is generated. No matter the value of topdown, the list of\n",
    "subdirectories is retrieved before the tuples for the directory and its\n",
    "subdirectories are generated.\n",
    "\n",
    "By default errors from the os.scandir() call are ignored.  If\n",
    "optional arg 'onerror' is specified, it should be a function; it\n",
    "will be called with one argument, an OSError instance.  It can\n",
    "report the error to continue with the walk, or raise the exception\n",
    "to abort the walk.  Note that the filename is available as the\n",
    "filename attribute of the exception object.\n",
    "\n",
    "By default, os.walk does not follow symbolic links to subdirectories on\n",
    "systems that support them.  In order to get this functionality, set the\n",
    "optional argument 'followlinks' to true.\n",
    "\n",
    "Caution:  if you pass a relative pathname for top, don't change the\n",
    "current working directory between resumptions of walk.  walk never\n",
    "changes the current directory, and assumes that the client doesn't\n",
    "either.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b0cf990f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is root  .\n",
      "This is dirs  ['.ipynb_checkpoints', 'data']\n",
      "This is files  ['DS_IO.ipynb', 'Hash_function.ipynb', 'PY_Algorithms.ipynb', 'PY_OOP.ipynb', 'PY_Pythonic.ipynb', 'Roughwork.ipynb', 'WQU_unit _one.ipynb']\n",
      "This is root  .\\.ipynb_checkpoints\n",
      "This is dirs  []\n",
      "This is files  ['DS_IO-checkpoint.ipynb', 'Hash_function-checkpoint.ipynb', 'PY_Algorithms-checkpoint.ipynb', 'PY_OOP-checkpoint.ipynb', 'PY_Pythonic-checkpoint.ipynb', 'Roughwork-checkpoint.ipynb', 'WQU_unit _one-checkpoint.ipynb']\n",
      "This is root  .\\data\n",
      "This is dirs  []\n",
      "This is files  ['my_data.txt', 'sample.txt', 'stock_prices.csv']\n"
     ]
    }
   ],
   "source": [
    "for root, dirs, files in os.walk('.'):\n",
    "    print('This is root ',root)\n",
    "    print('This is dirs ',dirs)\n",
    "    print('This is files ',files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db0c3fb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.ipynb_checkpoints']\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "for root,dirs, files in os.walk('.'):\n",
    "    print(dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ce003f14",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\\DS_IO.ipynb\n",
      ".\\Hash_function.ipynb\n",
      ".\\PY_Algorithms.ipynb\n",
      ".\\PY_OOP.ipynb\n",
      ".\\PY_Pythonic.ipynb\n",
      ".\\Roughwork.ipynb\n",
      ".\\WQU_unit _one.ipynb\n",
      ".\\.ipynb_checkpoints\\DS_IO-checkpoint.ipynb\n",
      ".\\.ipynb_checkpoints\\Hash_function-checkpoint.ipynb\n",
      ".\\.ipynb_checkpoints\\PY_Algorithms-checkpoint.ipynb\n",
      ".\\.ipynb_checkpoints\\PY_OOP-checkpoint.ipynb\n",
      ".\\.ipynb_checkpoints\\PY_Pythonic-checkpoint.ipynb\n",
      ".\\.ipynb_checkpoints\\Roughwork-checkpoint.ipynb\n",
      ".\\.ipynb_checkpoints\\WQU_unit _one-checkpoint.ipynb\n",
      ".\\data\\my_data.txt\n",
      ".\\data\\sample.txt\n",
      ".\\data\\stock_prices.csv\n"
     ]
    }
   ],
   "source": [
    "for root, dirs, files in os.walk('.'):\n",
    "    for file in files:\n",
    "        print(os.path.join(root, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1c417d86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DS_IO.ipynb\n",
      "Hash_function.ipynb\n",
      "my_data.txt\n",
      "PY_Algorithms.ipynb\n",
      "PY_OOP.ipynb\n",
      "PY_Pythonic.ipynb\n",
      "Roughwork.ipynb\n",
      "sample.txt\n",
      "stock_prices.csv\n",
      "WQU_unit _one.ipynb\n",
      "DS_IO-checkpoint.ipynb\n",
      "Hash_function-checkpoint.ipynb\n",
      "PY_Algorithms-checkpoint.ipynb\n",
      "PY_OOP-checkpoint.ipynb\n",
      "PY_Pythonic-checkpoint.ipynb\n",
      "Roughwork-checkpoint.ipynb\n",
      "WQU_unit _one-checkpoint.ipynb\n"
     ]
    }
   ],
   "source": [
    "for root, dirs, files in os.walk('.'):\n",
    "    for file in files:\n",
    "        print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "432e4d40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74e8ded9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DS_IO-checkpoint.ipynb\n",
      "Hash_function-checkpoint.ipynb\n",
      "PY_Algorithms-checkpoint.ipynb\n",
      "PY_OOP-checkpoint.ipynb\n",
      "PY_Pythonic-checkpoint.ipynb\n",
      "Roughwork-checkpoint.ipynb\n",
      "WQU_unit _one-checkpoint.ipynb\n"
     ]
    }
   ],
   "source": [
    "for i in files:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959feced",
   "metadata": {},
   "source": [
    "### CSV files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2669712",
   "metadata": {},
   "source": [
    "One of the simplest and most common formats forsaving data is the Comma Separated Value (CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b2bb5285",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Index', ' Name', ' Age'],\n",
       " ['0', ' Dylan', ' 28'],\n",
       " ['1', ' Terrance', ' 54'],\n",
       " ['2', ' Mya', ' 31']]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = []\n",
    "with open('./data/my_sample.txt', 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        table.append(line.strip().split(','))\n",
    "\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c5140557",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Index', ' Name', ' Age'],\n",
       " [0, ' Dylan', 28],\n",
       " [1, ' Terrance', 54],\n",
       " [2, ' Mya', 31]]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_table = []\n",
    "\n",
    "def parse_str(line):\n",
    "    if line[0] == \"Index\":\n",
    "        return line\n",
    "    \n",
    "    return [int(line[0]), line[1], int(line[2])]\n",
    "        \n",
    "with open('./data/my_sample.txt', 'r') as f:       \n",
    "    for line in f.readlines():\n",
    "        line = line.strip().split(',')\n",
    "        list_table.append(parse_str(line))\n",
    "\n",
    "list_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113e65fe",
   "metadata": {},
   "source": [
    "However, we can work with tabular data much more easily in a Pandas Dataframe. Pandas provides a read_csv mthod to read the data directly into a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3097d3a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dylan</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mya</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Name   Age\n",
       "Index              \n",
       "0       Dylan    28\n",
       "1         NaN    54\n",
       "2         Mya    31"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('./data/my_sample.txt', index_col = 'Index')\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a871a1",
   "metadata": {},
   "source": [
    "The read_csv method is very flexible to deal with the formatting of different data sets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b02fbc7",
   "metadata": {},
   "source": [
    "We can also use pandas to write CSV using the DataFrame's to_csv method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "13887c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'a' : [0, 3, 10], 'b' : [True, True, False]}).to_csv('./data/written_to_file.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c5b33973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ",a,b\n",
      "0,0,True\n",
      "1,3,True\n",
      "2,10,False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('./data/written_to_file.csv', 'r') as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "429697fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    a      b\n",
       "0   0   True\n",
       "1   3   True\n",
       "2  10  False"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./data/written_to_file.csv', index_col=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2169630",
   "metadata": {},
   "source": [
    "### JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431c859b",
   "metadata": {},
   "source": [
    "JSON stands for JavaScript Object Notation. JavaScript is a common language for creating web applications, and JSON files are used to collect and transmit information between JavaScript applications. as a result, a lot of data on the internet exists in the JSON file format. For example, Twitter and GoogleMaps use JSOn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44588997",
   "metadata": {},
   "source": [
    "A JSON file is essentially a data structure built out of nested distionaries and lists. Let's make our own example and then we'll examine an example downloaded from the internet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e96227d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'The Prophet',\n",
       "  'author': 'Khalil Gibran',\n",
       "  'genre': 'poetry',\n",
       "  'tags': ['religion',\n",
       "   'spiritualityphilosophy',\n",
       "   'Lebanon',\n",
       "   'Arabic',\n",
       "   'Middle East'],\n",
       "  'book_id': '811.19',\n",
       "  'copies': [{'edition_year': 1996, 'checkouts': 486, 'borrowed': False},\n",
       "   {'edition_year': 1996, 'checkouts': 443, 'borrowed': False}]},\n",
       " {'title': 'The Little Prince',\n",
       "  'author': 'Antoine de Saint-Exupery',\n",
       "  'genre': 'children',\n",
       "  'tags': ['fantasy', 'France', 'philosophy', 'illustrated', 'false'],\n",
       "  'id': '843.912',\n",
       "  'copies': [{'edition_year': 1983,\n",
       "    'checkouts': 634,\n",
       "    'borrowed': True,\n",
       "    'due_date': '2017/02/02'},\n",
       "   {'edition_year': 2015, 'checkouts': 41, 'borrowed': False}]}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book1 = {'title': 'The Prophet',\n",
    "        'author': 'Khalil Gibran',\n",
    "         'genre': 'poetry',\n",
    "         'tags': ['religion', 'spirituality' 'philosophy', 'Lebanon', 'Arabic', 'Middle East'],\n",
    "         'book_id': '811.19',\n",
    "         'copies': [{'edition_year' : 1996,\n",
    "                     'checkouts' : 486,\n",
    "                     'borrowed' : False},\n",
    "                    {'edition_year': 1996,\n",
    "                    'checkouts' : 443,\n",
    "                     'borrowed' : False\n",
    "                    }]\n",
    "        }\n",
    "\n",
    "book2 = {'title': 'The Little Prince',\n",
    "         'author': 'Antoine de Saint-Exupery',\n",
    "         'genre': 'children',\n",
    "         'tags': ['fantasy', 'France', 'philosophy', 'illustrated', 'false'],\n",
    "         'id': '843.912',\n",
    "         'copies': [{'edition_year':1983,\n",
    "                     'checkouts': 634,\n",
    "                     'borrowed': True,\n",
    "                     'due_date': '2017/02/02'},\n",
    "                    {'edition_year':2015,\n",
    "                     'checkouts': 41,\n",
    "                     'borrowed': False\n",
    "                    }]\n",
    "        }\n",
    "\n",
    "library = [book1, book2]\n",
    "library"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b56f3a0",
   "metadata": {},
   "source": [
    "It's convenient to store the information about the multiple copies as a list of dictionaries within the dictionary about the book, because every copy shares the same title, author, etc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b1d544",
   "metadata": {},
   "source": [
    "This structure is typical of JSON files. It has the advantage of reducing redundancy of data. We only store the author and title ones, even though there are multiple copies of the book. Also we don't store a due date  for copies that aren't checked out."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac17606",
   "metadata": {},
   "source": [
    "If we were to put this data in a table, we wouldhave to duplicate a lot of information. Also, since only one copy in our library is checked out, we also have a column with a lot of missing data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18f90b9",
   "metadata": {},
   "source": [
    "This is very wasteful. Since JSON files are meant to be shared quickly over the internet, it is important that they are small to reduce the amount of resources needed to store and transmit them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191cf9ad",
   "metadata": {},
   "source": [
    "We can write our library to disk using the JSON module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "533b85cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#note : json is just text structured in a particular way\n",
    "import json\n",
    "\n",
    "with open('./data/library.json', 'w') as f:\n",
    "    json.dump(library, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "95e56f0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'cat' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!cat ./data/library.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "37ac431e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"title\": \"The Prophet\",\n",
      "    \"author\": \"Khalil Gibran\",\n",
      "    \"genre\": \"poetry\",\n",
      "    \"tags\": [\n",
      "      \"religion\",\n",
      "      \"spiritualityphilosophy\",\n",
      "      \"Lebanon\",\n",
      "      \"Arabic\",\n",
      "      \"Middle East\"\n",
      "    ],\n",
      "    \"book_id\": \"811.19\",\n",
      "    \"copies\": [\n",
      "      {\n",
      "        \"edition_year\": 1996,\n",
      "        \"checkouts\": 486,\n",
      "        \"borrowed\": false\n",
      "      },\n",
      "      {\n",
      "        \"edition_year\": 1996,\n",
      "        \"checkouts\": 443,\n",
      "        \"borrowed\": false\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  {\n",
      "    \"title\": \"The Little Prince\",\n",
      "    \"author\": \"Antoine de Saint-Exupery\",\n",
      "    \"genre\": \"children\",\n",
      "    \"tags\": [\n",
      "      \"fantasy\",\n",
      "      \"France\",\n",
      "      \"philosophy\",\n",
      "      \"illustrated\",\n",
      "      \"false\"\n",
      "    ],\n",
      "    \"id\": \"843.912\",\n",
      "    \"copies\": [\n",
      "      {\n",
      "        \"edition_year\": 1983,\n",
      "        \"checkouts\": 634,\n",
      "        \"borrowed\": true,\n",
      "        \"due_date\": \"2017/02/02\"\n",
      "      },\n",
      "      {\n",
      "        \"edition_year\": 2015,\n",
      "        \"checkouts\": 41,\n",
      "        \"borrowed\": false\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "with open('./data/library.json', 'r') as f:\n",
    "    loaded_library = f.read()\n",
    "    \n",
    "print(loaded_library)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bc284aba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'The Prophet',\n",
       "  'author': 'Khalil Gibran',\n",
       "  'genre': 'poetry',\n",
       "  'tags': ['religion',\n",
       "   'spiritualityphilosophy',\n",
       "   'Lebanon',\n",
       "   'Arabic',\n",
       "   'Middle East'],\n",
       "  'book_id': '811.19',\n",
       "  'copies': [{'edition_year': 1996, 'checkouts': 486, 'borrowed': False},\n",
       "   {'edition_year': 1996, 'checkouts': 443, 'borrowed': False}]},\n",
       " {'title': 'The Little Prince',\n",
       "  'author': 'Antoine de Saint-Exupery',\n",
       "  'genre': 'children',\n",
       "  'tags': ['fantasy', 'France', 'philosophy', 'illustrated', 'false'],\n",
       "  'id': '843.912',\n",
       "  'copies': [{'edition_year': 1983,\n",
       "    'checkouts': 634,\n",
       "    'borrowed': True,\n",
       "    'due_date': '2017/02/02'},\n",
       "   {'edition_year': 2015, 'checkouts': 41, 'borrowed': False}]}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('./data/library.json', 'r') as f:\n",
    "    reloaded_library = json.load(f)\n",
    "    \n",
    "reloaded_library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "521ea98b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reloaded_library == library"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc136144",
   "metadata": {},
   "source": [
    "Pandas can also read json files with read_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f111d30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "127841cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>genre</th>\n",
       "      <th>tags</th>\n",
       "      <th>book_id</th>\n",
       "      <th>copies</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Prophet</td>\n",
       "      <td>Khalil Gibran</td>\n",
       "      <td>poetry</td>\n",
       "      <td>[religion, spiritualityphilosophy, Lebanon, Ar...</td>\n",
       "      <td>811.19</td>\n",
       "      <td>[{'edition_year': 1996, 'checkouts': 486, 'bor...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Little Prince</td>\n",
       "      <td>Antoine de Saint-Exupery</td>\n",
       "      <td>children</td>\n",
       "      <td>[fantasy, France, philosophy, illustrated, false]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'edition_year': 1983, 'checkouts': 634, 'bor...</td>\n",
       "      <td>843.912</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               title                    author     genre  \\\n",
       "0        The Prophet             Khalil Gibran    poetry   \n",
       "1  The Little Prince  Antoine de Saint-Exupery  children   \n",
       "\n",
       "                                                tags  book_id  \\\n",
       "0  [religion, spiritualityphilosophy, Lebanon, Ar...   811.19   \n",
       "1  [fantasy, France, philosophy, illustrated, false]      NaN   \n",
       "\n",
       "                                              copies       id  \n",
       "0  [{'edition_year': 1996, 'checkouts': 486, 'bor...      NaN  \n",
       "1  [{'edition_year': 1983, 'checkouts': 634, 'bor...  843.912  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.read_json('./data/library.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5281b60a",
   "metadata": {},
   "source": [
    "### Compressed files (Gzip)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b9aa18",
   "metadata": {},
   "source": [
    "Another way we save storage and network resources is by using compression. Many times data sets will contain patterns that can be used to reduce the amount of space needed to store the information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e156d441",
   "metadata": {},
   "source": [
    "A simple example is the following list of numbers: 10,10,10,2,3,3,3,3,3,50,50,1,1,50,10,10,10,10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cdddf95",
   "metadata": {},
   "source": [
    "Rather than writing out the full list of numbers(18 integers), we can represent the same information with only 14 members: (3, 10), (1,2),(5,3),(2,50),(2,1),(1,50),(4,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab44df6",
   "metadata": {},
   "source": [
    "We  have successfully reduced the amount of numbers we need to represent the same data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7896399b",
   "metadata": {},
   "source": [
    "In the world of data science, the most common compression is Gzip(which uses the deflate algorithm). Gzip files end with the extension .gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06440c08",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'charmap' codec can't decode byte 0x8d in position 625: character maps to <undefined>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "Input \u001b[1;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgzip\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./data/test_file.docx\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m----> 4\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m gzip\u001b[38;5;241m.\u001b[39mopen(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./data/gzip_file\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m      8\u001b[0m     f\u001b[38;5;241m.\u001b[39mwrite(data\u001b[38;5;241m.\u001b[39mencode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\encodings\\cp1252.py:23\u001b[0m, in \u001b[0;36mIncrementalDecoder.decode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, final\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m---> 23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcodecs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcharmap_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdecoding_table\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'charmap' codec can't decode byte 0x8d in position 625: character maps to <undefined>"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "\n",
    "with open('./data/test_file.docx', 'r') as f:\n",
    "    data = f.read()\n",
    "    \n",
    "\n",
    "with gzip.open('./data/gzip_file', 'wb') as f:\n",
    "    f.write(data.encode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ba7c6476",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget -P ./data/https://archive.org/stream/TheEpicofGilgamesh_201606/eog_djvu.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7881bb02",
   "metadata": {},
   "source": [
    "### Serialization : Pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f888787",
   "metadata": {},
   "source": [
    "Often we will want to save work in Python and come back to it later. However, that might be a machine learning model or some other complex object in Python. How do we save complex Python objects? Python has a module for this purpose called pickle. We can use pickle to write a binary file that contains all the information about a Python object. Later we can load that pickle file and reconstruct the object in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e4ed6ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_example = ['hello', {'a': 23, 'b': True}, (1, 2, 3), [['dogs', 'cats'], None]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b7b0713a",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "write() argument must be str, not list",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [45]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./data/pickle_example.txt\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m----> 2\u001b[0m     \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpickle_example\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: write() argument must be str, not list"
     ]
    }
   ],
   "source": [
    "with open('./data/pickle_example.txt', 'w') as f:\n",
    "    f.write(pickle_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e07c754",
   "metadata": {},
   "source": [
    "trying json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5a5ed463",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/pickle_example.txt', 'w') as f:\n",
    "    json.dump(pickle_example, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0472196a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hello', {'a': 23, 'b': True}, [1, 2, 3], [['dogs', 'cats'], None]]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('./data/pickle_example.txt', 'r') as f:\n",
    "    pickled_json = json.load(f)\n",
    "    \n",
    "pickled_json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab8c353",
   "metadata": {},
   "source": [
    "Using Pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7476e660",
   "metadata": {},
   "source": [
    "Pickle is capable of representing python arbitrary object and reconstructing to memory from disc exactly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "207685f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hello', {'a': 23, 'b': True}, (1, 2, 3), [['dogs', 'cats'], None]]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open('./data/pickle_example.pkl', 'wb') as f:\n",
    "    pickle.dump(pickle_example, f)\n",
    "    \n",
    "with open('./data/pickle_example.pkl', 'rb') as f:\n",
    "    reloaded_example = pickle.load(f)\n",
    "    \n",
    "reloaded_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "49d9582c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pickle_example == reloaded_example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0493458e",
   "metadata": {},
   "source": [
    "Pickle is an important tool for data scientists. Data processing and training machine learning models can take a long time, and it is useful to save checkpoints."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8b9f68",
   "metadata": {},
   "source": [
    "### NumPy file formats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0caf3697",
   "metadata": {},
   "source": [
    "NumPy also has methods for saving and loading data. They are also often used when working with image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0ebd6963",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.81466505, 0.94315638, 0.19423007, 0.30790716],\n",
       "       [0.44646576, 0.14831023, 0.64269213, 0.19052138],\n",
       "       [0.14457983, 0.59444781, 0.95180546, 0.41446375],\n",
       "       [0.46247811, 0.71568299, 0.35503824, 0.30609103]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "sample_array = np.random.random((4, 4))\n",
    "sample_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8a0f3598",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to save plain text\n",
    "np.savetxt('./data/sample_array.txt', sample_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2811cb3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.81466505 0.94315638 0.19423007 0.30790716]\n",
      " [0.44646576 0.14831023 0.64269213 0.19052138]\n",
      " [0.14457983 0.59444781 0.95180546 0.41446375]\n",
      " [0.46247811 0.71568299 0.35503824 0.30609103]]\n"
     ]
    }
   ],
   "source": [
    "print(np.loadtxt('./data/sample_array.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9761647a",
   "metadata": {},
   "source": [
    "to save as compressed binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b3a0ce80",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./data/sample_array.npy', sample_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "67241b60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'cat' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!cat ./data/sample_array.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "25a76f29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.81466505 0.94315638 0.19423007 0.30790716]\n",
      " [0.44646576 0.14831023 0.64269213 0.19052138]\n",
      " [0.14457983 0.59444781 0.95180546 0.41446375]\n",
      " [0.46247811 0.71568299 0.35503824 0.30609103]]\n"
     ]
    }
   ],
   "source": [
    "print(np.load('./data/sample_array.npy'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e749e94a",
   "metadata": {},
   "source": [
    "Topics used but not discused"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f90afa5",
   "metadata": {},
   "source": [
    "- BASH commands(!)\n",
    "- wget\n",
    "- str.split()\n",
    "- APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbac60d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
